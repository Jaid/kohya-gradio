{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dF_YX7yRzAo",
        "outputId": "9eed8183-b1c3-44c4-d79e-dbe51aeb70d8"
      },
      "outputs": [],
      "source": [
        "# @title Check environment\n",
        "!env | sort\n",
        "!python --version\n",
        "!pip list\n",
        "!nvidia-smi\n",
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9-0FBqw-WCE",
        "outputId": "fc624ba2-e576-4776-88ea-b6c59add4953"
      },
      "outputs": [],
      "source": [
        "# @title Clone\n",
        "!git clone https://github.com/Jaid/kohya-gradio.git\n",
        "%cd kohya-gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NY0gbHCLAhrk",
        "outputId": "816fdc6c-87e4-4a58-d0e4-e7a7302347df"
      },
      "outputs": [],
      "source": [
        "!python -m pip --disable-pip-version-check install --upgrade pip\n",
        "%pip install --disable-pip-version-check --requirement requirements_colab.txt --extra-index-url https://download.pytorch.org/whl/cu121 --extra-index-url https://pypi.nvidia.com\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRybQMnBnzSY"
      },
      "outputs": [],
      "source": [
        "%mkdir --parents private\n",
        "import requests\n",
        "def download(url, target):\n",
        "  print(f\"{url} â†’ {target}\")\n",
        "  response = requests.get(url, allow_redirects=True)\n",
        "  response.raise_for_status()\n",
        "  with open(target, 'wb') as output_file:\n",
        "    output_file.write(response.content)\n",
        "vaeLocation = 'https://huggingface.co/stabilityai/sdxl-vae/resolve/main/sdxl_vae.safetensors' # @param {type:\"string\"}\n",
        "download(vaeLocation, '/content/vae.safetensors')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uxo_u6AZydZ"
      },
      "outputs": [],
      "source": [
        "# @title Check CUDA support in PyTorch\n",
        "!pip show torch\n",
        "import torch\n",
        "print(torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(torch.cuda.get_device_name(0))\n",
        "!pip show tensorflow\n",
        "import tensorflow as tf\n",
        "print(tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '.venv' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'd:/git/.fork/kohya-gradio/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "!accelerate config\n",
        "!accelerate test\n",
        "import accelerate\n",
        "print(accelerate.utils.get_max_memory())\n",
        "print(accelerate.utils.is_bf16_available())\n",
        "print(accelerate.utils.is_xla_available())\n",
        "print(accelerate.utils.is_deepspeed_available())\n",
        "print(accelerate.utils.is_cuda_available())\n",
        "print(accelerate.utils.is_safetensors_available())\n",
        "print(accelerate.utils.is_tpu_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-uHk9V0EJqpi"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "dim = 64 # @param {type:\"integer\"}\n",
        "imageCount = 4 # @param {type:\"integer\"}\n",
        "epochs = 20 # @param {type:\"integer\"}\n",
        "steps = imageCount * epochs\n",
        "alpha = math.trunc(dim / 2)\n",
        "warmupStepsPercent = 0 # @param {type:\"integer\"}\n",
        "learningRate = 0.0000004 # @param {type:\"number\"}\n",
        "fullPrecision = False # @param {type:\"boolean\"}\n",
        "saveVram = True # @param {type:\"boolean\"}\n",
        "wandbKey = '' # @param {type:\"string\"}\n",
        "outputFormat = 'safetensors' # @param [\"safetensors\", \"checkpoint\"]\n",
        "alwaysSave = True # @param {type:\"boolean\"}\n",
        "useLycoris = True # @param {type:\"boolean\"}\n",
        "adaptiveOptimizer = False # @param {type:\"boolean\"}\n",
        "sample = False # @param {type:\"boolean\"}\n",
        "\n",
        "if warmupStepsPercent:\n",
        "  warmupSteps = math.floor(steps * warmupStepsPercent / 100)\n",
        "else:\n",
        "  warmupSteps = 0\n",
        "\n",
        "accelerateArguments = [\n",
        "]\n",
        "\n",
        "launchArguments = [\n",
        "  '--pretrained_model_name_or_path',\n",
        "  # \"$rootMixed/private/checkpoint.safetensors\"\n",
        "  'stabilityai/stable-diffusion-xl-base-1.0',\n",
        "  '--vae',\n",
        "  \"/content/vae.safetensors\",\n",
        "  '--train_data_dir',\n",
        "  \"img\",\n",
        "  '--output_dir',\n",
        "  \"/content/out/model\",\n",
        "  '--logging_dir',\n",
        "  \"/content/out/log\",\n",
        "  '--resolution',\n",
        "  '1024,1024',\n",
        "  '--save_model_as',\n",
        "  outputFormat,\n",
        "  '--text_encoder_lr',\n",
        "  '0.0001',\n",
        "  '--unet_lr',\n",
        "  '0.0001',\n",
        "  '--network_dim',\n",
        "  dim,\n",
        "  '--network_alpha',\n",
        "  alpha,\n",
        "  '--output_name',\n",
        "  'trained',\n",
        "  '--max_train_steps',\n",
        "  steps,\n",
        "  # '--max_train_epochs'\n",
        "  # 10\n",
        "  '--no_half_vae',\n",
        "  '--caption_extension',\n",
        "  '.txt',\n",
        "  '--cache_latents',\n",
        "]\n",
        "if useLycoris:\n",
        "  launchArguments += [\n",
        "    '--network_module',\n",
        "    'lycoris.kohya',\n",
        "    '--network_args',\n",
        "    'preset=full',\n",
        "    'algo=full',\n",
        "    'rank_dropout=0',\n",
        "    'module_dropout=0',\n",
        "    'use_tucker=False',\n",
        "    'use_scalar=False',\n",
        "    'rank_dropout_scale=True',\n",
        "    'train_norm=True',\n",
        "  ]\n",
        "else:\n",
        "  launchArguments += [\n",
        "    '--network_module',\n",
        "    'networks.lora',\n",
        "  ]\n",
        "if adaptiveOptimizer:\n",
        "  launchArguments += [\n",
        "    '--optimizer_type',\n",
        "    'adafactor',\n",
        "    '--optimizer',\n",
        "    'adafactor',\n",
        "    '--optimizer_args',\n",
        "    'scale_parameter=False',\n",
        "    'relative_step=False',\n",
        "    'warmup_init=False',\n",
        "  ]\n",
        "else:\n",
        "  launchArguments += [\n",
        "    '--optimizer_type',\n",
        "  ]\n",
        "  if saveVram:\n",
        "    launchArguments += [\n",
        "      # 'adamw8bit'\n",
        "      'adamw',\n",
        "    ]\n",
        "  else:\n",
        "    launchArguments += [\n",
        "      'adamw',\n",
        "    ]\n",
        "if alwaysSave:\n",
        "  launchArguments += [\n",
        "    '--save_every_n_epochs',\n",
        "    1,\n",
        "  ]\n",
        "if not learningRate:\n",
        "  launchArguments += [\n",
        "    '--lr_scheduler',\n",
        "    'adafactor',\n",
        "  ]\n",
        "elif warmupSteps:\n",
        "  launchArguments += [\n",
        "    '--lr_scheduler',\n",
        "    'constant_with_warmup',\n",
        "    '--lr_warmup_steps',\n",
        "    warmupSteps,\n",
        "    '--learning_rate',\n",
        "    learningRate,\n",
        "  ]\n",
        "else:\n",
        "  launchArguments += [\n",
        "    '--lr_scheduler',\n",
        "    'constant',\n",
        "  ]\n",
        "if saveVram:\n",
        "  launchArguments += [\n",
        "    '--xformers',\n",
        "  ]\n",
        "if fullPrecision:\n",
        "  launchArguments += [\n",
        "    '--mixed_precision',\n",
        "    'no',\n",
        "    '--save_precision',\n",
        "    'float',\n",
        "  ]\n",
        "else:\n",
        "  launchArguments += [\n",
        "    '--mixed_precision',\n",
        "    'bf16',\n",
        "    '--save_precision',\n",
        "    'bf16',\n",
        "    # '--full_bf16',\n",
        "  ]\n",
        "if sample:\n",
        "  launchArguments += [\n",
        "    '--sample_sampler',\n",
        "    'euler_a',\n",
        "    '--sample_prompts',\n",
        "    \"$rootMixed/out/model/sample/prompt.txt\",\n",
        "    '--sample_every_n_epochs',\n",
        "    1,\n",
        "  ]\n",
        "if wandbKey:\n",
        "  launchArguments += [\n",
        "    '--log_with',\n",
        "    'wandb',\n",
        "    '--wandb_api_key',\n",
        "    wandbKey,\n",
        "  ]\n",
        "launchArguments += [\n",
        "  '--metadata_title',\n",
        "  'SinansWoche',\n",
        "]\n",
        "\n",
        "print(f\"accelerate launch {accelerateArguments} sdxl_train_network.py {launchArguments}\")\n",
        "!accelerate launch {accelerateArguments} sdxl_train_network.py {launchArguments}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
